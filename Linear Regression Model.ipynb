{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "704d7af0",
   "metadata": {},
   "source": [
    "**Predicting the Average Minutes Played of NBA Draft Picks**\n",
    "\n",
    "Ranking draft prospects is a common occurance among NBA fans. Doing so however is no easy task as the NBA draft is often reffered to as a 'crapshoot' due to it's unpredictable nature. This model serves as an attempt to evaluate draft prospects based on draft position, college statistics and draft combine data. \n",
    "\n",
    "The first step of evaluating draft prospects is choosing a metric to evaluate their success. While plenty of publicly avaiable  advanced metrics exist, all are flawed to varying degrees. More importantly however, advanced metrics compare NBA players to eachother and while this is useful for evaluating the best players in the league, it's rather useless for comparing low-end role players who often don't even play enough minutes to be considered by these metrics. For example, out of all second round picks from 2003-2013, 48% played less than 3 years in the NBA with 26% never playing a single minute in the league. Since second round picks make up roughly 47% of the players in my dataset it would be foolish to choose an evaluation metric that would invalidate half of the data I'm working with. This lead to me choosing minutes played to evaluate player succes as at the end of the day good NBA players play more minutes then bad ones. \n",
    "\n",
    "**METHOD**\n",
    "\n",
    "This project can be broken up to three main sections: Collecting Data, Cleaning Data, and Constructing Model.\n",
    "\n",
    "A more detailed methodology is shown below:\n",
    "\n",
    "**Collecting Data:**\n",
    "\n",
    "    -Compiling URLs and table IDs\n",
    "    -Scrape Basketball Reference for NCAA statistics\n",
    "    -Use nba_api to gather draft combine data, draft results and minutes played\n",
    "    -Export data to csv\n",
    "\n",
    "**Cleaning Data:**\n",
    "\n",
    "    -Drop irrelevant columns\n",
    "    -Adress null values\n",
    "    -Preform appropriate unit conversions\n",
    "    -Merge college stats, draft combine data, draft results and minutes played to a single csv\n",
    "\n",
    "**Constructing Model:**\n",
    "\n",
    "    -Import modules and dataset\n",
    "    -Isolate predictor variables\n",
    "    -Seperate training and testing data\n",
    "    -Train main model\n",
    "    -Train control model and combine results\n",
    "    -Run model\n",
    "    -Next steps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d242b3",
   "metadata": {},
   "source": [
    "**Importing Modules**\n",
    "\n",
    "The following modules are required to run this notebook:\n",
    "    \n",
    "    -Pandas\n",
    "    -Ridge from sklearn.linear_model\n",
    "    -mean_squared_error from sklearn.metrics\n",
    "    -numpy\n",
    "    -scipy and scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54edfadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.stats as stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7359c71f",
   "metadata": {},
   "source": [
    "**Importing Dataset**\n",
    "\n",
    "Imports the dataset used by the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "167882e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gets the data from the scraper and deletes the index column\n",
    "main_df = pd.read_csv('merged.csv')\n",
    "del main_df['Unnamed: 0']\n",
    "del main_df['BPM']\n",
    "main_df = main_df.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3223b17",
   "metadata": {},
   "source": [
    "**Isolating Predictor Variables**\n",
    "\n",
    "Drops all columns which are not predictor variables from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbb8ca59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gets Predidctor variables\n",
    "def get_predictors():\n",
    "        columns_to_drop = ['Total Minutes', \n",
    "                         'Seasons Played',\n",
    "                         'Player',\n",
    "                         'POSITION',\n",
    "                         'Year',\n",
    "                         'STANDING_REACH_FT_IN',\n",
    "                         'DRAFT_NUMBER.1',\n",
    "                         'Average Minutes',\n",
    "                         'DRAFT_NUMBER']\n",
    "        \n",
    "\n",
    "        predictors = (main_df.drop(columns = columns_to_drop)).columns\n",
    "        return predictors\n",
    "        '''\n",
    "        if year in shuttleRun:\n",
    "            predictors.drop(columns = year)\n",
    "        elif year in benchPress:\n",
    "        '''    \n",
    "\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34454f7f",
   "metadata": {},
   "source": [
    "**Seperating training and testing data**\n",
    "\n",
    "Chose roughly 20% of the data to be used for testing used the rest for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59027ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_years = [2004,2009,2012,2017]\n",
    "training_years = []\n",
    "for year in range(2000,2021):\n",
    "    if year not in testing_years:\n",
    "        training_years.append(year)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db57602",
   "metadata": {},
   "source": [
    "**Training Main Model**\n",
    "\n",
    "Used sklearn to create a ridge regression model. Used mean squared error as an error metric to compare with the control model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20887b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_training(training_years, testing_years, predictors):\n",
    "    \n",
    "    #Getting Predictors\n",
    "    column_to_predict = 'Average Minutes'\n",
    "    \n",
    "    #Training the model\n",
    "    train = main_df[main_df['Year'].isin(training_years)]\n",
    "    test = main_df[main_df['Year'].isin(testing_years)]\n",
    "    reg = Ridge(alpha = 0.1)\n",
    "    reg.fit(train[predictors], train[column_to_predict])\n",
    "\n",
    "    #Getting predicitons in a dataframe\n",
    "    predictions = reg.predict(test[predictors])\n",
    "    predictions = pd.DataFrame(predictions, columns = ['Predictions'], index = test.index)\n",
    "    combination = pd.concat([test[['Player', column_to_predict]], predictions], axis = 1)\n",
    "    \n",
    "    #Getting Mean Square Error\n",
    "    mse = mean_squared_error(combination[column_to_predict], combination['Predictions'])\n",
    "    \n",
    "    #Gets a clutter free df 'clean' which neatly displays information\n",
    "    important_columns = ['Player',  column_to_predict,  'Predictions']\n",
    "    clean = combination.loc[:,important_columns]\n",
    "    clean['Predictions'] = round(clean['Predictions'], 0)\n",
    "    clean[column_to_predict] = round(clean[column_to_predict], 0)\n",
    "    clean['Predictions'] = clean['Predictions'].astype(int)\n",
    "    clean[column_to_predict] = clean[column_to_predict].astype(int)\n",
    "    clean['Difference'] = clean[column_to_predict] - clean['Predictions'] \n",
    "    \n",
    "    return(clean, mse)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8943ea0",
   "metadata": {},
   "source": [
    "**Train Control Model and Combine Results**\n",
    "\n",
    "A control model was constructed identically to the main model with draft position being the sole predictor instead of a combination of draft postion, college stats and draft combine data that was used in the main model. Draft position was used as a control as the NBA draft is essentially a ranking of draft prospects done by NBA teams and draft position is by far the most signifcant predictor of minutes played. Therefore using draft position as a control allows us to compare the results of our model with the opinion of NBA front offices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "059e7635",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(training_years, testing_years):\n",
    "    \n",
    "    main_model = model_training(training_years, testing_years, get_predictors())\n",
    "    main_model_df = main_model[0]\n",
    "    main_model_mse = main_model[1]\n",
    "    \n",
    "    control_predictor = ['DRAFT_NUMBER']\n",
    "    control_model = model_training(training_years, testing_years, control_predictor)\n",
    "    control_model_df = control_model[0]\n",
    "    control_model_mse = control_model[1]\n",
    "    \n",
    "    columns_to_rename = {'Predictions': 'Control_Predictions',\n",
    "                         'Difference': 'Control_Difference'}\n",
    "    control_model_df = control_model_df.rename(columns = columns_to_rename)\n",
    "    \n",
    "    #Merge Control and Main Dataframes\n",
    "    merged = main_model_df.merge(control_model_df[['Player', 'Control_Predictions', 'Control_Difference']], how='left', on='Player')\n",
    "    merged = merged.sort_values('Predictions', ascending = False)\n",
    "    \n",
    "    #Final Statement\n",
    "    ratio = main_model_mse/control_model_mse\n",
    "    percent = (1 - ratio) * 100\n",
    "    percent = round(percent, 2)\n",
    "    statement = 'The MSE of the model was ' + str(percent) + '% lower than the control model'\n",
    "    string = 'mse control: ' + str(round(control_model_mse,0)) + '\\n' + 'mse: ' + str(round(main_model_mse,0))\n",
    "    \n",
    "    print(statement)\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1f832f",
   "metadata": {},
   "source": [
    "**Run Model**\n",
    "\n",
    "The results of my model is shown below. Based on the mean squared error of both models, my model preformed 5.76% worse at predicting average minutes played then NBA front offices did. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d5e1797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE of the model was -5.76% lower than the control model\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Average Minutes</th>\n",
       "      <th>Predictions</th>\n",
       "      <th>Difference</th>\n",
       "      <th>Control_Predictions</th>\n",
       "      <th>Control_Difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Stephen Curry</td>\n",
       "      <td>2181</td>\n",
       "      <td>1810</td>\n",
       "      <td>371</td>\n",
       "      <td>1383</td>\n",
       "      <td>798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Blake Griffin</td>\n",
       "      <td>1984</td>\n",
       "      <td>1749</td>\n",
       "      <td>235</td>\n",
       "      <td>1522</td>\n",
       "      <td>462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Tyreke Evans</td>\n",
       "      <td>1824</td>\n",
       "      <td>1593</td>\n",
       "      <td>231</td>\n",
       "      <td>1453</td>\n",
       "      <td>371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Terrence Williams</td>\n",
       "      <td>730</td>\n",
       "      <td>1500</td>\n",
       "      <td>-770</td>\n",
       "      <td>1291</td>\n",
       "      <td>-561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Luol Deng</td>\n",
       "      <td>2064</td>\n",
       "      <td>1398</td>\n",
       "      <td>666</td>\n",
       "      <td>1383</td>\n",
       "      <td>681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Jaron Blossomgame</td>\n",
       "      <td>441</td>\n",
       "      <td>300</td>\n",
       "      <td>141</td>\n",
       "      <td>180</td>\n",
       "      <td>261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Miles Plumlee</td>\n",
       "      <td>808</td>\n",
       "      <td>281</td>\n",
       "      <td>527</td>\n",
       "      <td>944</td>\n",
       "      <td>-136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Andrew Nicholson</td>\n",
       "      <td>816</td>\n",
       "      <td>236</td>\n",
       "      <td>580</td>\n",
       "      <td>1106</td>\n",
       "      <td>-290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Festus Ezeli</td>\n",
       "      <td>799</td>\n",
       "      <td>118</td>\n",
       "      <td>681</td>\n",
       "      <td>851</td>\n",
       "      <td>-52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Bernard James</td>\n",
       "      <td>252</td>\n",
       "      <td>-282</td>\n",
       "      <td>534</td>\n",
       "      <td>782</td>\n",
       "      <td>-530</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>115 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Player  Average Minutes  Predictions  Difference  \\\n",
       "19      Stephen Curry             2181         1810         371   \n",
       "26      Blake Griffin             1984         1749         235   \n",
       "23       Tyreke Evans             1824         1593         231   \n",
       "44  Terrence Williams              730         1500        -770   \n",
       "1           Luol Deng             2064         1398         666   \n",
       "..                ...              ...          ...         ...   \n",
       "94  Jaron Blossomgame              441          300         141   \n",
       "76      Miles Plumlee              808          281         527   \n",
       "74   Andrew Nicholson              816          236         580   \n",
       "53       Festus Ezeli              799          118         681   \n",
       "57      Bernard James              252         -282         534   \n",
       "\n",
       "    Control_Predictions  Control_Difference  \n",
       "19                 1383                 798  \n",
       "26                 1522                 462  \n",
       "23                 1453                 371  \n",
       "44                 1291                -561  \n",
       "1                  1383                 681  \n",
       "..                  ...                 ...  \n",
       "94                  180                 261  \n",
       "76                  944                -136  \n",
       "74                 1106                -290  \n",
       "53                  851                 -52  \n",
       "57                  782                -530  \n",
       "\n",
       "[115 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abc = model(training_years, testing_years)\n",
    "abc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef72925",
   "metadata": {},
   "source": [
    "**Next Steps**\n",
    "\n",
    "As of now the first iteration of this model is complete however that does not mean this project is finished. Some next steps are shown below:\n",
    "\n",
    "    **-Visualize data**\n",
    "        -Add plot comparing data\n",
    "        -As of right now there is no real visualization of the data and just adding a simple plot comparing the two models could go a long way\n",
    "        \n",
    "    **-Improve the algorithm**\n",
    "        -Find the optimal alpha value\n",
    "            -The alpha value was chosen by manually testing and looking at the results, therefore there is definetly room for improvement in this department\n",
    "        -Test for overfitting\n",
    "            -No test was undertaken to see if the model was overfitting/underfitting the data so it's likely improvements can be made here\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
